{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Y4Na8IpBJoVC",
        "outputId": "a118b1aa-6c4e-438f-8306-4f95ed82ff9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import dlib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, concatenate\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# مسیر دیتاست\n",
        "DATASET_PATH = \"/content/drive/My Drive/Drowsiness Status\"\n",
        "CATEGORIES = [\"Not_Sleepy\", \"Sleepy\"]\n",
        "IMAGE_SIZE = 64\n",
        "\n",
        "# بارگذاری و پردازش تصاویر\n",
        "def load_dataset():\n",
        "    images = []\n",
        "    labels = []\n",
        "    features = []\n",
        "\n",
        "    detector = dlib.get_frontal_face_detector()\n",
        "    predictor = dlib.shape_predictor(\"/content/drive/MyDrive/shape_predictor_68_face_landmarks.dat\")\n",
        "\n",
        "    for label, category in enumerate(CATEGORIES):\n",
        "        category_path = os.path.join(DATASET_PATH, category)\n",
        "        for img_name in os.listdir(category_path):\n",
        "            img_path = os.path.join(category_path, img_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                faces = detector(gray)\n",
        "\n",
        "                for face in faces:\n",
        "                    landmarks = predictor(gray, face)\n",
        "                    left_eye = (landmarks.part(36).x, landmarks.part(36).y)\n",
        "                    right_eye = (landmarks.part(45).x, landmarks.part(45).y)\n",
        "                    mouth = (landmarks.part(62).x, landmarks.part(62).y)\n",
        "\n",
        "                    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "                    img = img / 255.0  # نرمال‌سازی\n",
        "\n",
        "                    images.append(img)\n",
        "                    labels.append(label)\n",
        "                    features.append([left_eye[0] - right_eye[0], mouth[1] - left_eye[1]])\n",
        "                    break  # یک چهره در تصویر کافی است\n",
        "\n",
        "    return np.array(images), np.array(features), np.array(labels)\n",
        "\n",
        "# بارگذاری داده‌ها\n",
        "X_images, X_features, y = load_dataset()\n",
        "y = to_categorical(y, num_classes=len(CATEGORIES))\n",
        "\n",
        "# تقسیم داده‌ها\n",
        "X_train_images, X_test_images, X_train_features, X_test_features, y_train, y_test = train_test_split(\n",
        "    X_images, X_features, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# مدل CNN برای تصاویر\n",
        "image_input = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "x = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
        "x = MaxPooling2D(2, 2)(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = MaxPooling2D(2, 2)(x)\n",
        "x = Flatten()(x)\n",
        "\n",
        "# مدل MLP برای ویژگی‌ها\n",
        "feature_input = Input(shape=(2,))  # دو ویژگی عددی\n",
        "y = Dense(32, activation='relu')(feature_input)\n",
        "\n",
        "# ترکیب دو مدل\n",
        "combined = concatenate([x, y])\n",
        "output = Dense(len(CATEGORIES), activation='softmax')(combined)\n",
        "\n",
        "model = Model(inputs=[image_input, feature_input], outputs=output)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# آموزش مدل\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "history= model.fit([X_train_images, X_train_features], y_train, epochs=10, batch_size=32, validation_data=([X_test_images, X_test_features], y_test), callbacks=[early_stopping])\n",
        "\n",
        "# 7. ارزیابی مدل\n",
        "loss, accuracy = model.evaluate(X_test_images, y_test)\n",
        "print(f\"دقت مدل: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# 8. ذخیره مدل\n",
        "model.save(\"/content/drive/My Drive/sleep_detection_model.h5\")\n",
        "print(\"مدل ذخیره شد.\")\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# رسم نمودار دقت\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# رسم نمودار خطا\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# تنظیمات مدل و اندازه تصویر\n",
        "IMAGE_SIZE = (64, 64)\n",
        "CATEGORIES = [\"Not_Sleepy\", \"Sleepy\"]\n",
        "\n",
        "# بارگذاری مدل\n",
        "model = tf.keras.models.load_model(\"/content/drive/My Drive/sleep_detection_model.h5\")\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# تابع پیش‌بینی\n",
        "def predict_frame(frame):\n",
        "    if frame is None or frame.size == 0:\n",
        "        raise ValueError(\"Error: The input frame is empty or None!\")\n",
        "    try:\n",
        "        img = cv2.resize(frame, IMAGE_SIZE)\n",
        "        img = img / 255.0\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        prediction = model.predict(img)\n",
        "        class_index = np.argmax(prediction)\n",
        "        confidence = prediction[0][class_index] * 100\n",
        "        return CATEGORIES[class_index], confidence\n",
        "    except Exception as e:\n",
        "        print(f\"Error during prediction: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# اتصال به دوربین\n",
        "cap = cv2.VideoCapture(0)\n",
        "if cap.isOpened():\n",
        "    print(\"Video stream opened successfully!\")\n",
        "else:\n",
        "    print(\"Error: Unable to open video stream\")\n",
        "\n",
        "# پردازش و نمایش تصویر\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret or frame is None:\n",
        "        print(\"Error: Failed to capture frame\")\n",
        "        break\n",
        "\n",
        "    # پیش‌بینی\n",
        "    result, confidence = predict_frame(frame)\n",
        "    if result is not None:\n",
        "        cv2.putText(frame, f\"{result} ({confidence:.2f}%)\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "    # نمایش تصویر\n",
        "    cv2.imshow(\"Live Camera\", frame)\n",
        "\n",
        "    # خروج با زدن کلید 'q'\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# آزادسازی دوربین\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ],
      "metadata": {
        "id": "fnVYyWRzqUSt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}