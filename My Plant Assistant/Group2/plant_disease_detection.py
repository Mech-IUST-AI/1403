# -*- coding: utf-8 -*-
"""plant_disease_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12pOboc8OL0ib2C22nVr3_78evIl7HBgc

Downloading the datadet
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("yogeshwaran005/plant-disease-detection")

print("Path to dataset files:", path)

"""note: I merged the dataset with another dataset of kaggle. The final dataset is the combination of the two datasets in the links below:

1- https://www.kaggle.com/datasets/yogeshwaran005/plants-disease-detection

2- https://www.kaggle.com/datasets/emmarex/plantdisease

Connecting to google drive
"""

from google.colab import drive
drive.mount('/content/drive')

import os
os.listdir("/content/drive/My Drive/plant-disease-detection/Plant Disease Detection")

import os

# مسیر فولدر اصلی دیتاست را مشخص کنید
base_path = "/content/drive/My Drive/plant-disease-detection/Plant Disease Detection"

# پیمایش فولدرها و شمارش تصاویر در هر پوشه
def count_images_in_folders(base_path):
    if not os.path.exists(base_path):
        print("Invalid base path. Please check the folder path.")
        return

    for plant in sorted(os.listdir(base_path)):
        plant_path = os.path.join(base_path, plant)
        if os.path.isdir(plant_path):
            print(f"\nPlant: {plant}")
            for disease in sorted(os.listdir(plant_path)):
                disease_path = os.path.join(plant_path, disease)
                if os.path.isdir(disease_path):
                    image_count = len([file for file in os.listdir(disease_path) if os.path.isfile(os.path.join(disease_path, file)) and file.lower().endswith(('.jpg', '.png', '.jpeg'))])
                    print(f"  {disease}: {image_count} images")

# اجرا
count_images_in_folders(base_path)

import os

def display_folder_structure_with_counts(base_path, indent=0):
    if not os.path.exists(base_path):
        print("Invalid base path. Please check the folder path.")
        return

    # بررسی محتوای فولدر
    for item in sorted(os.listdir(base_path)):
        item_path = os.path.join(base_path, item)
        if os.path.isdir(item_path):
            print(" " * indent + f"📁 {item}/")
            display_folder_structure_with_counts(item_path, indent + 4)
        else:
            if item.lower().endswith(('.jpg', '.png', '.jpeg')):
                continue
            print(" " * indent + f"📄 {item}")

    # شمارش تصاویر
    image_count = len([file for file in os.listdir(base_path)
                       if os.path.isfile(os.path.join(base_path, file)) and file.lower().endswith(('.jpg', '.png', '.jpeg'))])
    if image_count > 0:
        print(" " * indent + f"📸 {image_count} images")

# مسیر فولدر اصلی دیتاست را مشخص کنید
base_path = "/content/drive/My Drive/plant-disease-detection/Plant Disease Detection"

# اجرا
display_folder_structure_with_counts(base_path)

"""preprocess"""

import os
import shutil
import random

# نسبت‌های تقسیم‌بندی
test_ratio = 0.15
val_ratio = 0.15

# تابع تقسیم داده‌ها
def split_data_for_plant(plant_path, output_base_path):
    if not os.path.exists(plant_path):
        print("Invalid plant path. Please check the folder path.")
        return

    plant_name = os.path.basename(plant_path)
    output_path = os.path.join(output_base_path, plant_name)
    train_path = os.path.join(output_path, "Train")
    val_path = os.path.join(output_path, "Validation")
    test_path = os.path.join(output_path, "Test")

    for folder in [train_path, val_path, test_path]:
        os.makedirs(folder, exist_ok=True)

    print(f"Processing plant: {plant_name}")
    for disease in sorted(os.listdir(plant_path)):
        disease_path = os.path.join(plant_path, disease)
        if os.path.isdir(disease_path):
            files = [f for f in os.listdir(disease_path)
                     if os.path.isfile(os.path.join(disease_path, f)) and f.lower().endswith(('.jpg', '.png', '.jpeg'))]
            random.shuffle(files)
            total_files = len(files)

            test_count = int(total_files * test_ratio)
            val_count = int(total_files * val_ratio)

            test_files = files[:test_count]
            val_files = files[test_count:test_count + val_count]
            train_files = files[test_count + val_count:]

            for file_set, target_path in zip([train_files, val_files, test_files], [train_path, val_path, test_path]):
                disease_output_path = os.path.join(target_path, disease)
                os.makedirs(disease_output_path, exist_ok=True)
                for file in file_set:
                    shutil.copy(os.path.join(disease_path, file), os.path.join(disease_output_path, file))

            print(f"  {disease}: Train={len(train_files)}, Validation={len(val_files)}, Test={len(test_files)}")

"""اجرا برای گیاه corn"""

# مسیر گیاه و فولدر خروجی
corn_path = "/content/drive/My Drive/plant-disease-detection/Plant Disease Detection/Corn"
output_base_path = "/content/drive/My Drive/plant-disease-detection/Processed Data"

# اجرا
split_data_for_plant(corn_path, output_base_path)

import os

# مسیر فولدر دیتاست تقسیم‌بندی شده برای گیاه Corn را مشخص کنید
base_path = "/content/drive/My Drive/plant-disease-detection/Processed Data/Corn"

# پیمایش فولدرهای Train، Validation و Test و شمارش تصاویر
def check_data_structure(base_path):
    if not os.path.exists(base_path):
        print("Invalid base path. Please check the folder path.")
        return

    for folder in ['Train', 'Validation', 'Test']:
        print(f"\n{folder} folder contents:")
        folder_path = os.path.join(base_path, folder)
        if os.path.isdir(folder_path):
            for disease in sorted(os.listdir(folder_path)):
                disease_path = os.path.join(folder_path, disease)
                if os.path.isdir(disease_path):
                    image_count = len([file for file in os.listdir(disease_path) if os.path.isfile(os.path.join(disease_path, file)) and file.lower().endswith(('.jpg', '.png', '.jpeg'))])
                    print(f"  {disease}: {image_count} images")

# اجرا
check_data_structure(base_path)

"""data augmentation"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Data Augmentation برای داده‌های آموزش
train_datagen = ImageDataGenerator(
    rescale=1./255,  # نرمال‌سازی پیکسل‌ها
    rotation_range=40,  # چرخش تصاویر
    width_shift_range=0.2,  # تغییر موقعیت عرضی
    height_shift_range=0.2,  # تغییر موقعیت عمودی
    shear_range=0.2,  # چرخش تصاویر
    zoom_range=0.2,  # بزرگ‌نمایی
    horizontal_flip=True,  # برعکس کردن تصاویر
    fill_mode='nearest'  # پر کردن پیکسل‌های خالی
)

# برای داده‌های اعتبارسنجی و تست فقط نرمال‌سازی انجام می‌دهیم
test_datagen = ImageDataGenerator(rescale=1./255)

# بارگذاری داده‌ها
train_generator = train_datagen.flow_from_directory(
    '/content/drive/My Drive/plant-disease-detection/Processed Data/Corn/Train',
    target_size=(224, 224),  # تغییر اندازه تصاویر
    batch_size=32,
    class_mode='categorical'  # از برچسب‌های دسته‌بندی استفاده می‌کنیم
)

validation_generator = test_datagen.flow_from_directory(
    '/content/drive/My Drive/plant-disease-detection/Processed Data/Corn/Validation',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

test_generator = test_datagen.flow_from_directory(
    '/content/drive/My Drive/plant-disease-detection/Processed Data/Corn/Test',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

"""model building"""

from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models

# بارگذاری مدل VGG16 از پیش آموزش‌دیده بدون لایه‌های خروجی
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# لایه‌های جدید مدل
model = models.Sequential()
model.add(base_model)
model.add(layers.Flatten())  # صاف کردن ویژگی‌ها
model.add(layers.Dense(512, activation='relu'))  # لایه Fully Connected
model.add(layers.Dense(4, activation='softmax'))  # تعداد دسته‌ها را مطابق با بیماری‌های گیاهی (در اینجا 4) تنظیم کنید

# تنظیمات مدل
base_model.trainable = False  # برای جلوگیری از آموزش مجدد لایه‌های پیش‌آموزش دیده

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# نمایش ساختار مدل
model.summary()

"""model training"""

history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=10,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size
)

"""ارزیابی مدل"""

test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)
print(f"Test accuracy: {test_acc * 100:.2f}%")

# نام مخصوص گیاه Corn
model_name = 'corn_plant_disease_model.h5'

# ذخیره مدل با نام مخصوص گیاه
model.save(model_name)

# مسیر دلخواه برای ذخیره مدل
model_save_path = '/content/drive/My Drive/models/corn_plant_disease_model.h5'

# ذخیره مدل
model.save(model_save_path)

print(f"Model saved at: {model_save_path}")

import os

# مشخص کردن فولدر برای جستجو
model_folder = "/content/drive/My Drive/models"

# لیست کردن فایل‌های داخل پوشه
model_files = [f for f in os.listdir(model_folder) if f.endswith('.h5')]

# نمایش فایل‌ها
print("Model files found:")
for file in model_files:
    print(f"- {file}")

from tensorflow.keras.models import load_model
model = load_model('/content/drive/My Drive/models/corn_plant_disease_model.h5')

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# بارگذاری داده‌های تست
test_datagen = ImageDataGenerator(rescale=1./255)

test_generator = test_datagen.flow_from_directory(
    '/content/drive/My Drive/plant-disease-detection/Processed Data/Corn/Test',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False  # مهم: ترتیب داده‌ها تغییر نکند
)

# پیش‌بینی نتایج برای داده‌های تست
y_pred = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)
y_pred_classes = np.argmax(y_pred, axis=1)  # تبدیل خروجی به کلاس‌های پیش‌بینی شده

# برچسب‌های واقعی
y_true = test_generator.classes

# حذف پیش‌بینی‌های اضافی و برچسب‌های واقعی اضافی
y_true = y_true[:len(y_pred_classes)]
y_pred_classes = y_pred_classes[:len(y_true)]

# ایجاد ماتریس سردرگمی
cm = confusion_matrix(y_true, y_pred_classes)

# رسم ماتریس سردرگمی
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

"""تست بگیریم :))"""

from google.colab import files
from tensorflow.keras.preprocessing import image
import numpy as np
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt

# بارگذاری مدل ذخیره شده
model_path = '/content/drive/My Drive/models/corn_plant_disease_model.h5'
model = load_model(model_path)

# آپلود تصویر
uploaded = files.upload()

# گرفتن نام فایل آپلود شده
img_path = next(iter(uploaded))

mg = image.load_img(img_path, target_size=(224, 224))
img_array = image.img_to_array(img)
# بارگذاری و پیش‌پردازش تصویر
img_array = np.expand_dims(img_array, axis=0)  # تبدیل به آرایه با ابعاد (1, 224, 224, 3)
img_array /= 255.0  # نرمال‌سازی پیکسل‌ها

# پیش‌بینی بیماری گیاه
predictions = model.predict(img_array)

# نمایش نتایج
class_names = ['common_rust', 'grey_leaf_spot', 'healthy', 'northern_leaf_blight']  # لیست دسته‌ها
predicted_class = class_names[np.argmax(predictions)]

# نمایش تصویر
plt.imshow(img)
plt.title(f"Predicted Disease: {predicted_class}")
plt.axis('off')
plt.show()

print(f"Predicted Disease: {predicted_class}")

"""برای گیاه Tomato

preprocess
"""

# مسیر گیاه و فولدر خروجی
corn_path = "/content/drive/My Drive/plant-disease-detection/Plant Disease Detection/Tomato"
output_base_path = "/content/drive/My Drive/plant-disease-detection/Processed Data"

# اجرا
split_data_for_plant(corn_path, output_base_path)

import os

# مسیر فولدر دیتاست تقسیم‌بندی شده برای گیاه Corn را مشخص کنید
base_path = "/content/drive/My Drive/plant-disease-detection/Processed Data/Tomato"

# پیمایش فولدرهای Train، Validation و Test و شمارش تصاویر
def check_data_structure(base_path):
    if not os.path.exists(base_path):
        print("Invalid base path. Please check the folder path.")
        return

    for folder in ['Train', 'Validation', 'Test']:
        print(f"\n{folder} folder contents:")
        folder_path = os.path.join(base_path, folder)
        if os.path.isdir(folder_path):
            for disease in sorted(os.listdir(folder_path)):
                disease_path = os.path.join(folder_path, disease)
                if os.path.isdir(disease_path):
                    image_count = len([file for file in os.listdir(disease_path) if os.path.isfile(os.path.join(disease_path, file)) and file.lower().endswith(('.jpg', '.png', '.jpeg'))])
                    print(f"  {disease}: {image_count} images")

# اجرا
check_data_structure(base_path)

import os
import shutil

# تابع برای حذف فولدرها و داده‌های داخل آنها
def remove_folders(base_path):
    for folder in ['Train', 'Validation', 'Test']:
        folder_path = os.path.join(base_path, folder)
        if os.path.exists(folder_path):
            shutil.rmtree(folder_path)  # حذف فولدر و محتوای داخل آن
            print(f"Deleted {folder} folder.")

# مسیر فولدر دیتاست تقسیم‌بندی شده برای گیاه Tomato
base_path = "/content/drive/My Drive/plant-disease-detection/Processed Data/Tomato"

# حذف فولدرهای قبلی
remove_folders(base_path)

# اکنون می‌توانید کد تقسیم داده‌ها را دوباره اجرا کنید:
# نسبت‌های تقسیم‌بندی
test_ratio = 0.15
val_ratio = 0.15

# تابع تقسیم داده‌ها
def split_data_for_plant(plant_path, output_base_path):
    if not os.path.exists(plant_path):
        print("Invalid plant path. Please check the folder path.")
        return

    plant_name = os.path.basename(plant_path)
    output_path = os.path.join(output_base_path, plant_name)
    train_path = os.path.join(output_path, "Train")
    val_path = os.path.join(output_path, "Validation")
    test_path = os.path.join(output_path, "Test")

    for folder in [train_path, val_path, test_path]:
        os.makedirs(folder, exist_ok=True)

    print(f"Processing plant: {plant_name}")
    for disease in sorted(os.listdir(plant_path)):
        disease_path = os.path.join(plant_path, disease)
        if os.path.isdir(disease_path):
            files = [f for f in os.listdir(disease_path)
                     if os.path.isfile(os.path.join(disease_path, f)) and f.lower().endswith(('.jpg', '.png', '.jpeg'))]
            random.shuffle(files)
            total_files = len(files)

            test_count = int(total_files * test_ratio)
            val_count = int(total_files * val_ratio)

            test_files = files[:test_count]
            val_files = files[test_count:test_count + val_count]
            train_files = files[test_count + val_count:]

            for file_set, target_path in zip([train_files, val_files, test_files], [train_path, val_path, test_path]):
                disease_output_path = os.path.join(target_path, disease)
                os.makedirs(disease_output_path, exist_ok=True)
                for file in file_set:
                    shutil.copy(os.path.join(disease_path, file), os.path.join(disease_output_path, file))

            print(f"  {disease}: Train={len(train_files)}, Validation={len(val_files)}, Test={len(test_files)}")

# مسیر گیاه و فولدر خروجی
corn_path = "/content/drive/My Drive/plant-disease-detection/Plant Disease Detection/Tomato"
output_base_path = "/content/drive/My Drive/plant-disease-detection/Processed Data"

# اجرا
split_data_for_plant(corn_path, output_base_path)

import os

# مسیر فولدر دیتاست تقسیم‌بندی شده برای گیاه Tomato
base_path = "/content/drive/My Drive/plant-disease-detection/Processed Data/Tomato"

# تابع برای شمارش تصاویر در هر دسته
def check_data_structure(base_path):
    if not os.path.exists(base_path):
        print("Invalid base path. Please check the folder path.")
        return

    for folder in ['Train', 'Validation', 'Test']:
        print(f"\n{folder} folder contents:")
        folder_path = os.path.join(base_path, folder)
        if os.path.isdir(folder_path):
            for disease in sorted(os.listdir(folder_path)):
                disease_path = os.path.join(folder_path, disease)
                if os.path.isdir(disease_path):
                    image_count = len([file for file in os.listdir(disease_path) if os.path.isfile(os.path.join(disease_path, file)) and file.lower().endswith(('.jpg', '.png', '.jpeg'))])
                    print(f"  {disease}: {image_count} images")

# اجرا
check_data_structure(base_path)

import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# مسیر فولدرهای داده‌ها
train_dir = "/content/drive/My Drive/plant-disease-detection/Processed Data/Tomato/Train"
val_dir = "/content/drive/My Drive/plant-disease-detection/Processed Data/Tomato/Validation"
test_dir = "/content/drive/My Drive/plant-disease-detection/Processed Data/Tomato/Test"

# ایجاد ImageDataGenerators برای داده‌های آموزشی، اعتبارسنجی و تست
train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=30, width_shift_range=0.2,
                                   height_shift_range=0.2, shear_range=0.2, zoom_range=0.2,
                                   horizontal_flip=True, fill_mode='nearest')

val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(train_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')
val_generator = val_datagen.flow_from_directory(val_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')
test_generator = test_datagen.flow_from_directory(test_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')

# بارگذاری مدل MobileNetV2 از پیش آموزش‌دیده
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# لایه‌های جدید مدل
model = models.Sequential()
model.add(base_model)
model.add(layers.GlobalAveragePooling2D())  # کاهش ابعاد ویژگی‌ها
model.add(layers.Dense(512, activation='relu'))  # لایه Fully Connected
model.add(layers.Dense(train_generator.num_classes, activation='softmax'))  # تعداد دسته‌ها مطابق با بیماری‌ها

# تنظیمات مدل
base_model.trainable = False  # جلوگیری از آموزش لایه‌های پیش‌آموزش دیده

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# آموزش مدل
history = model.fit(train_generator, epochs=10, validation_data=val_generator)

# ارزیابی مدل روی داده‌های تست
test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Test accuracy: {test_accuracy * 100:.2f}%")

# ذخیره مدل به صورت HDF5
model.save("/content/drive/My Drive/models/Tomato_plant_disease_model.h5")
print("Model saved successfully!")

import os

# مشخص کردن فولدر برای جستجو
model_folder = "/content/drive/My Drive/models"

# لیست کردن فایل‌های داخل پوشه
model_files = [f for f in os.listdir(model_folder) if f.endswith('.h5')]

# نمایش فایل‌ها
print("Model files found:")
for file in model_files:
    print(f"- {file}")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# دریافت پیش‌بینی‌ها
y_pred = model.predict(test_generator)
y_pred_classes = np.argmax(y_pred, axis=1)

# دریافت کلاس‌های واقعی
y_true = test_generator.classes

# بررسی ابعاد y_true و y_pred_classes
if len(y_true) != len(y_pred_classes):
    print("Mismatch in y_true and y_pred_classes lengths!")
else:
    # ایجاد ماتریس سردرگمی
    cm = confusion_matrix(y_true, y_pred_classes)
    class_names = list(test_generator.class_indices.keys())  # نام کلاس‌ها

    # رسم ماتریس سردرگمی
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
    disp.plot(cmap=plt.cm.Blues, xticks_rotation="vertical")
    plt.title("Confusion Matrix")
    plt.show()

"""برای گیاه Rice

preprocessing
"""

# مسیر گیاه و فولدر خروجی
corn_path = "/content/drive/My Drive/plant-disease-detection/Plant Disease Detection/Rice"
output_base_path = "/content/drive/My Drive/plant-disease-detection/Processed Data"

# اجرا
split_data_for_plant(corn_path, output_base_path)

import os

# مسیر فولدر دیتاست تقسیم‌بندی شده برای گیاه Corn را مشخص کنید
base_path = "/content/drive/My Drive/plant-disease-detection/Processed Data/Rice"

# پیمایش فولدرهای Train، Validation و Test و شمارش تصاویر
def check_data_structure(base_path):
    if not os.path.exists(base_path):
        print("Invalid base path. Please check the folder path.")
        return

    for folder in ['Train', 'Validation', 'Test']:
        print(f"\n{folder} folder contents:")
        folder_path = os.path.join(base_path, folder)
        if os.path.isdir(folder_path):
            for disease in sorted(os.listdir(folder_path)):
                disease_path = os.path.join(folder_path, disease)
                if os.path.isdir(disease_path):
                    image_count = len([file for file in os.listdir(disease_path) if os.path.isfile(os.path.join(disease_path, file)) and file.lower().endswith(('.jpg', '.png', '.jpeg'))])
                    print(f"  {disease}: {image_count} images")

# اجرا
check_data_structure(base_path)

import os
import shutil

# تابع برای حذف فولدرها و داده‌های داخل آنها
def remove_folders(base_path):
    for folder in ['Train', 'Validation', 'Test']:
        folder_path = os.path.join(base_path, folder)
        if os.path.exists(folder_path):
            shutil.rmtree(folder_path)  # حذف فولدر و محتوای داخل آن
            print(f"Deleted {folder} folder.")

# مسیر فولدر دیتاست تقسیم‌بندی شده برای گیاه Tomato
base_path = "/content/drive/My Drive/plant-disease-detection/Processed Data/Rice"

# حذف فولدرهای قبلی
remove_folders(base_path)

# اکنون می‌توانید کد تقسیم داده‌ها را دوباره اجرا کنید:
# نسبت‌های تقسیم‌بندی
test_ratio = 0.15
val_ratio = 0.15

# تابع تقسیم داده‌ها
def split_data_for_plant(plant_path, output_base_path):
    if not os.path.exists(plant_path):
        print("Invalid plant path. Please check the folder path.")
        return

    plant_name = os.path.basename(plant_path)
    output_path = os.path.join(output_base_path, plant_name)
    train_path = os.path.join(output_path, "Train")
    val_path = os.path.join(output_path, "Validation")
    test_path = os.path.join(output_path, "Test")

    for folder in [train_path, val_path, test_path]:
        os.makedirs(folder, exist_ok=True)

    print(f"Processing plant: {plant_name}")
    for disease in sorted(os.listdir(plant_path)):
        disease_path = os.path.join(plant_path, disease)
        if os.path.isdir(disease_path):
            files = [f for f in os.listdir(disease_path)
                     if os.path.isfile(os.path.join(disease_path, f)) and f.lower().endswith(('.jpg', '.png', '.jpeg'))]
            random.shuffle(files)
            total_files = len(files)

            test_count = int(total_files * test_ratio)
            val_count = int(total_files * val_ratio)

            test_files = files[:test_count]
            val_files = files[test_count:test_count + val_count]
            train_files = files[test_count + val_count:]

            for file_set, target_path in zip([train_files, val_files, test_files], [train_path, val_path, test_path]):
                disease_output_path = os.path.join(target_path, disease)
                os.makedirs(disease_output_path, exist_ok=True)
                for file in file_set:
                    shutil.copy(os.path.join(disease_path, file), os.path.join(disease_output_path, file))

            print(f"  {disease}: Train={len(train_files)}, Validation={len(val_files)}, Test={len(test_files)}")

# مسیر گیاه و فولدر خروجی
corn_path = "/content/drive/My Drive/plant-disease-detection/Plant Disease Detection/Rice"
output_base_path = "/content/drive/My Drive/plant-disease-detection/Processed Data"

# اجرا
split_data_for_plant(corn_path, output_base_path)

import os

# مسیر فولدر دیتاست تقسیم‌بندی شده برای گیاه Tomato
base_path = "/content/drive/My Drive/plant-disease-detection/Processed Data/Rice"

# تابع برای شمارش تصاویر در هر دسته
def check_data_structure(base_path):
    if not os.path.exists(base_path):
        print("Invalid base path. Please check the folder path.")
        return

    for folder in ['Train', 'Validation', 'Test']:
        print(f"\n{folder} folder contents:")
        folder_path = os.path.join(base_path, folder)
        if os.path.isdir(folder_path):
            for disease in sorted(os.listdir(folder_path)):
                disease_path = os.path.join(folder_path, disease)
                if os.path.isdir(disease_path):
                    image_count = len([file for file in os.listdir(disease_path) if os.path.isfile(os.path.join(disease_path, file)) and file.lower().endswith(('.jpg', '.png', '.jpeg'))])
                    print(f"  {disease}: {image_count} images")

# اجرا
check_data_structure(base_path)

"""data augmentation"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Data Augmentation برای داده‌های آموزش
train_datagen = ImageDataGenerator(
    rescale=1./255,  # نرمال‌سازی پیکسل‌ها
    rotation_range=40,  # چرخش تصاویر
    width_shift_range=0.2,  # تغییر موقعیت عرضی
    height_shift_range=0.2,  # تغییر موقعیت عمودی
    shear_range=0.2,  # چرخش تصاویر
    zoom_range=0.2,  # بزرگ‌نمایی
    horizontal_flip=True,  # برعکس کردن تصاویر
    fill_mode='nearest'  # پر کردن پیکسل‌های خالی
)

# برای داده‌های اعتبارسنجی و تست فقط نرمال‌سازی انجام می‌دهیم
test_datagen = ImageDataGenerator(rescale=1./255)

# بارگذاری داده‌ها
train_generator = train_datagen.flow_from_directory(
    '/content/drive/My Drive/plant-disease-detection/Processed Data/Rice/Train',
    target_size=(224, 224),  # تغییر اندازه تصاویر
    batch_size=32,
    class_mode='categorical'  # از برچسب‌های دسته‌بندی استفاده می‌کنیم
)

validation_generator = test_datagen.flow_from_directory(
    '/content/drive/My Drive/plant-disease-detection/Processed Data/Rice/Validation',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

test_generator = test_datagen.flow_from_directory(
    '/content/drive/My Drive/plant-disease-detection/Processed Data/Rice/Test',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

"""model building"""

from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models

# بارگذاری مدل VGG16 از پیش آموزش‌دیده بدون لایه‌های خروجی
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# لایه‌های جدید مدل
model = models.Sequential()
model.add(base_model)
model.add(layers.Flatten())  # صاف کردن ویژگی‌ها
model.add(layers.Dense(512, activation='relu'))  # لایه Fully Connected
model.add(layers.Dense(4, activation='softmax'))  # تعداد دسته‌ها را مطابق با بیماری‌های گیاهی (در اینجا 4) تنظیم کنید

# تنظیمات مدل
base_model.trainable = False  # برای جلوگیری از آموزش مجدد لایه‌های پیش‌آموزش دیده

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# نمایش ساختار مدل
model.summary()

"""model training"""

history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=10,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size
)

test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)
print(f"Test accuracy: {test_acc * 100:.2f}%")

# نام مخصوص گیاه Corn
model_name = 'Rice_plant_disease_model.h5'

# ذخیره مدل با نام مخصوص گیاه
model.save(model_name)

# مسیر دلخواه برای ذخیره مدل
model_save_path = '/content/drive/My Drive/models/Rice_plant_disease_model.h5'

# ذخیره مدل
model.save(model_save_path)

print(f"Model saved at: {model_save_path}")

import os

# مشخص کردن فولدر برای جستجو
model_folder = "/content/drive/My Drive/models"

# لیست کردن فایل‌های داخل پوشه
model_files = [f for f in os.listdir(model_folder) if f.endswith('.h5')]

# نمایش فایل‌ها
print("Model files found:")
for file in model_files:
    print(f"- {file}")

from tensorflow.keras.models import load_model
model = load_model('/content/drive/My Drive/models/Rice_plant_disease_model.h5')

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# بارگذاری داده‌های تست
test_datagen = ImageDataGenerator(rescale=1./255)

test_generator = test_datagen.flow_from_directory(
    '/content/drive/My Drive/plant-disease-detection/Processed Data/Rice/Test',
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False  # مهم: ترتیب داده‌ها تغییر نکند
)

# پیش‌بینی نتایج برای داده‌های تست
y_pred = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size)
y_pred_classes = np.argmax(y_pred, axis=1)  # تبدیل خروجی به کلاس‌های پیش‌بینی شده

# برچسب‌های واقعی
y_true = test_generator.classes

# حذف پیش‌بینی‌های اضافی و برچسب‌های واقعی اضافی
y_true = y_true[:len(y_pred_classes)]
y_pred_classes = y_pred_classes[:len(y_true)]

# ایجاد ماتریس سردرگمی
cm = confusion_matrix(y_true, y_pred_classes)

# رسم ماتریس سردرگمی
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

"""برای گیاه wheat

preprocess
"""

# مسیر گیاه و فولدر خروجی
corn_path = "/content/drive/My Drive/plant-disease-detection/Plant Disease Detection/Wheat"
output_base_path = "/content/drive/My Drive/plant-disease-detection/Processed Data"

# اجرا
split_data_for_plant(corn_path, output_base_path)

import os

# مسیر فولدر دیتاست تقسیم‌بندی شده برای گیاه Corn را مشخص کنید
base_path = "/content/drive/My Drive/plant-disease-detection/Processed Data/Wheat"

# پیمایش فولدرهای Train، Validation و Test و شمارش تصاویر
def check_data_structure(base_path):
    if not os.path.exists(base_path):
        print("Invalid base path. Please check the folder path.")
        return

    for folder in ['Train', 'Validation', 'Test']:
        print(f"\n{folder} folder contents:")
        folder_path = os.path.join(base_path, folder)
        if os.path.isdir(folder_path):
            for disease in sorted(os.listdir(folder_path)):
                disease_path = os.path.join(folder_path, disease)
                if os.path.isdir(disease_path):
                    image_count = len([file for file in os.listdir(disease_path) if os.path.isfile(os.path.join(disease_path, file)) and file.lower().endswith(('.jpg', '.png', '.jpeg'))])
                    print(f"  {disease}: {image_count} images")

# اجرا
check_data_structure(base_path)

import os
import shutil

# تابع برای حذف فولدرها و داده‌های داخل آنها
def remove_folders(base_path):
    for folder in ['Train', 'Validation', 'Test']:
        folder_path = os.path.join(base_path, folder)
        if os.path.exists(folder_path):
            shutil.rmtree(folder_path)  # حذف فولدر و محتوای داخل آن
            print(f"Deleted {folder} folder.")

# مسیر فولدر دیتاست تقسیم‌بندی شده برای گیاه Tomato
base_path = "/content/drive/My Drive/plant-disease-detection/Processed Data/Wheat"

# حذف فولدرهای قبلی
remove_folders(base_path)

# اکنون می‌توانید کد تقسیم داده‌ها را دوباره اجرا کنید:
# نسبت‌های تقسیم‌بندی
test_ratio = 0.15
val_ratio = 0.15

# تابع تقسیم داده‌ها
def split_data_for_plant(plant_path, output_base_path):
    if not os.path.exists(plant_path):
        print("Invalid plant path. Please check the folder path.")
        return

    plant_name = os.path.basename(plant_path)
    output_path = os.path.join(output_base_path, plant_name)
    train_path = os.path.join(output_path, "Train")
    val_path = os.path.join(output_path, "Validation")
    test_path = os.path.join(output_path, "Test")

    for folder in [train_path, val_path, test_path]:
        os.makedirs(folder, exist_ok=True)

    print(f"Processing plant: {plant_name}")
    for disease in sorted(os.listdir(plant_path)):
        disease_path = os.path.join(plant_path, disease)
        if os.path.isdir(disease_path):
            files = [f for f in os.listdir(disease_path)
                     if os.path.isfile(os.path.join(disease_path, f)) and f.lower().endswith(('.jpg', '.png', '.jpeg'))]
            random.shuffle(files)
            total_files = len(files)

            test_count = int(total_files * test_ratio)
            val_count = int(total_files * val_ratio)

            test_files = files[:test_count]
            val_files = files[test_count:test_count + val_count]
            train_files = files[test_count + val_count:]

            for file_set, target_path in zip([train_files, val_files, test_files], [train_path, val_path, test_path]):
                disease_output_path = os.path.join(target_path, disease)
                os.makedirs(disease_output_path, exist_ok=True)
                for file in file_set:
                    shutil.copy(os.path.join(disease_path, file), os.path.join(disease_output_path, file))

            print(f"  {disease}: Train={len(train_files)}, Validation={len(val_files)}, Test={len(test_files)}")

# مسیر گیاه و فولدر خروجی
corn_path = "/content/drive/My Drive/plant-disease-detection/Plant Disease Detection/Wheat"
output_base_path = "/content/drive/My Drive/plant-disease-detection/Processed Data"

# اجرا
split_data_for_plant(corn_path, output_base_path)

import os

# مسیر فولدر دیتاست تقسیم‌بندی شده برای گیاه Tomato
base_path = "/content/drive/My Drive/plant-disease-detection/Processed Data/Wheat"

# تابع برای شمارش تصاویر در هر دسته
def check_data_structure(base_path):
    if not os.path.exists(base_path):
        print("Invalid base path. Please check the folder path.")
        return

    for folder in ['Train', 'Validation', 'Test']:
        print(f"\n{folder} folder contents:")
        folder_path = os.path.join(base_path, folder)
        if os.path.isdir(folder_path):
            for disease in sorted(os.listdir(folder_path)):
                disease_path = os.path.join(folder_path, disease)
                if os.path.isdir(disease_path):
                    image_count = len([file for file in os.listdir(disease_path) if os.path.isfile(os.path.join(disease_path, file)) and file.lower().endswith(('.jpg', '.png', '.jpeg'))])
                    print(f"  {disease}: {image_count} images")

# اجرا
check_data_structure(base_path)

import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# مسیر فولدرهای داده‌ها
train_dir = "/content/drive/My Drive/plant-disease-detection/Processed Data/Wheat/Train"
val_dir = "/content/drive/My Drive/plant-disease-detection/Processed Data/Wheat/Validation"
test_dir = "/content/drive/My Drive/plant-disease-detection/Processed Data/Wheat/Test"

# ایجاد ImageDataGenerators برای داده‌های آموزشی، اعتبارسنجی و تست
train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=30, width_shift_range=0.2,
                                   height_shift_range=0.2, shear_range=0.2, zoom_range=0.2,
                                   horizontal_flip=True, fill_mode='nearest')

val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(train_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')
val_generator = val_datagen.flow_from_directory(val_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')
test_generator = test_datagen.flow_from_directory(test_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')

# بارگذاری مدل MobileNetV2 از پیش آموزش‌دیده
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# لایه‌های جدید مدل
model = models.Sequential()
model.add(base_model)
model.add(layers.GlobalAveragePooling2D())  # کاهش ابعاد ویژگی‌ها
model.add(layers.Dense(512, activation='relu'))  # لایه Fully Connected
model.add(layers.Dense(train_generator.num_classes, activation='softmax'))  # تعداد دسته‌ها مطابق با بیماری‌ها

# تنظیمات مدل
base_model.trainable = False  # جلوگیری از آموزش لایه‌های پیش‌آموزش دیده

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# آموزش مدل
history = model.fit(train_generator, epochs=10, validation_data=val_generator)

# ارزیابی مدل روی داده‌های تست
test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Test accuracy: {test_accuracy * 100:.2f}%")

# ذخیره مدل به صورت HDF5
model.save("/content/drive/My Drive/plant-disease-detection/models/Wheat_plant_disease_model.h5")
print("Model saved successfully!")

import os

# مشخص کردن فولدر برای جستجو
model_folder = "/content/drive/My Drive/plant-disease-detection/models"

# لیست کردن فایل‌های داخل پوشه
model_files = [f for f in os.listdir(model_folder) if f.endswith('.h5')]

# نمایش فایل‌ها
print("Model files found:")
for file in model_files:
    print(f"- {file}")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay


y_pred = model.predict(test_generator)
y_pred_classes = np.argmax(y_pred, axis=1)


y_true = test_generator.classes

# بررسی ابعاد y_true و y_pred_classes
if len(y_true) != len(y_pred_classes):
    print("Mismatch in y_true and y_pred_classes lengths!")
else:
    # ایجاد ماتریس سردرگمی
    cm = confusion_matrix(y_true, y_pred_classes)
    class_names = list(test_generator.class_indices.keys())  # نام کلاس‌ها

    # رسم ماتریس سردرگمی
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
    disp.plot(cmap=plt.cm.Blues, xticks_rotation="vertical")
    plt.title("Confusion Matrix")
    plt.show()

"""فراخوانی"""

from google.colab import files
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import numpy as np
import matplotlib.pyplot as plt

# تعریف مدل‌ها، دسته‌ها و راه‌حل‌ها برای هر گیاه
models = {
    "Corn": {
    "model_path": "/content/drive/My Drive/plant-disease-detection/models/corn_plant_disease_model.h5",
    "class_names": ['common_rust', 'grey_leaf_spot', 'healthy', 'northern_leaf_blight'],
    "solutions": {
        'healthy': "گیاه شما سالم می‌باشد.",
        'grey_leaf_spot': "کاهش رطوبت برگ‌ها با آبیاری مناسب و جلوگیری از آبیاری بارانی، استفاده از قارچ‌کش‌هایی مانند مانکوزب، فلوکونازول یا کلروتالونیل",
        'common_rust': "آبیاری قطره‌ای برای کاهش رطوبت روی برگ‌ها، استفاده از قارچ‌کش‌های تماسی مانند پروپیکونازول یا فلوکونازول",
        'northern_leaf_blight': "استفاده از قارچ‌کش‌های سیستمیک مانند متالاکسیل یا فوزاریوم، حذف برگ‌های آلوده و جلوگیری از رشد آن‌ها"
      }
    },
    "Tomato": {
        "model_path": "/content/drive/My Drive/plant-disease-detection/models/Tomato_plant_disease_model.h5",
        "class_names": [
            'Tomato_Bacterial_spot', 'Tomato_Early_blight', 'Tomato_Late_blight',
            'Tomato_Leaf_Mold', 'Tomato_Septoria_leaf_spot', 'Tomato_Spider_mites_Two_spotted_spider_mite',
            'Tomato__Target_Spot', 'Tomato__Tomato_YellowLeaf__Curl_Virus',
            'Tomato_healthy'
        ],
        "solutions": {
            'Tomato_Healthy': "گیاه شما سالم می‌باشد.",
            'Tomato__Target_Spot': "تناوب زراعی، آبیاری قطره‌ای، قارچ‌کش‌هایی مانند کلروتالونیل.",
            'Tomato__Tomato_YellowLeaf__Curl_Virus': "کنترل مگس سفید با حشره‌کش‌ها و پوشاندن بوته‌ها.",
            'Tomato_Bacterial_spot': "جلوگیری از آبیاری بارانی، ترکیبات مسی.",
            'Tomato_Early_blight': "تهویه مناسب، قارچ‌کش‌هایی مانند مانکوزب.",
            'Tomato_Late_blight': "ضدعفونی بذرها، حذف بقایای گیاهی، قارچ‌کش‌های سیستمیک.",
            'Tomato_Leaf_Mold': "تهویه مناسب، قارچ‌کش‌هایی مانند کلروتالونیل.",
            'Tomato_Septoria_leaf_spot': "حذف برگ‌های آلوده، استفاده از مانکوزب.",
            'Tomato_Spider_mites_Two_spotted_spider_mite': "استفاده از کفشدوزک‌ها و آفت‌کش‌های طبیعی."
        }
    },
    "Rice": {
        "model_path": "/content/drive/My Drive/plant-disease-detection/models/Rice_plant_disease_model.h5",
        "class_names": ['Rice___Brown_Spot', 'Rice___Leaf_Blast', 'Rice___Neck_Blast', 'Rice_healthy'],
        "solutions": {
            'Rice_healthy': "گیاه شما سالم می‌باشد.",
            'Rice___Brown_Spot': "رعایت فاصله کاشت مناسب و جلوگیری از تراکم بیش از حد گیاهان، تنظیم آبیاری به‌گونه‌ای که رطوبت اضافی روی برگ‌ها جمع نشود، استفاده از قارچ‌کش‌هایی مانند مانکوزب، پِریدابن یا فوزاریوم",
            'Rice___Leaf_Blast': "استفاده از تناوب زراعی برای کاهش بقای پاتوژن‌ها در خاک، جلوگیری از آبیاری بیش از حد و اطمینان از تهویه خوب در مزرع، استفاده از قارچ‌کش‌های سیستمیک مانند متالاکسیل یا فوزاریوم",
            'Rice___Neck_Blast': "رعایت فاصله کاشت برای بهبود گردش هوا و کاهش رطوبت، استفاده از قارچ‌کش‌های سیستمیک مانند متالاکسیل یا تریفلوزول"
        }
    },
    "Wheat": {
    "model_path": "/content/drive/My Drive/plant-disease-detection/models/Wheat_plant_disease_model.h5",
    "class_names": [
        'Wheat___Brown_Rust', 'Wheat___Yellow_Rust', 'Wheat_healthy'
    ],
    "solutions": {
        'Wheat_healthy': "گیاه شما سالم می‌باشد.",
        'Wheat___Brown_Rust': "تناوب زراعی با گیاهانی که میزبان بیماری نیستند (مثلاً با استفاده از حبوبات)، استفاده از قارچ‌کش‌های تماسی مانند پروپیکونازول یا فلوکونازول، در صورت شیوع گسترده، استفاده از ترکیب قارچ‌کش‌ها به‌صورت متناوب برای کاهش مقاومت پاتوژن‌ها",
        'Wheat___Yellow_Rust': "انتخاب مکان‌های کشت مناسب با تهویه خوب برای جلوگیری از رطوبت بالا، انتخاب زمان مناسب کاشت برای جلوگیری از شیوع زودهنگام بیماری، استفاده از قارچ‌کش‌های سیستمیک و تماسی مانند تریفلوسول و پروپیکونازول"
      }
    },
}

# تابع پیش‌بینی تصویر
def predict_image(model, class_names, image_path):
    # بارگذاری و پیش‌پردازش تصویر
    img = load_img(image_path, target_size=(224, 224))
    img_array = img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)

    # پیش‌بینی
    prediction = model.predict(img_array)
    predicted_class_index = np.argmax(prediction)
    confidence = prediction[0][predicted_class_index]

    return class_names[predicted_class_index], confidence

# انتخاب گیاه
print("لطفاً یکی از گیاه‌های زیر را انتخاب کنید: Corn, Tomato, Rice, Wheat")
plant_choice = input("انتخاب گیاه: ").strip()

# بررسی انتخاب و بارگذاری مدل مرتبط
if plant_choice in models:
    plant_info = models[plant_choice]
    model = load_model(plant_info["model_path"])
    print(f"Model for {plant_choice} loaded successfully!")

    # آپلود فایل تصویر
    print("لطفاً یک تصویر آپلود کنید:")
    uploaded = files.upload()

    # پیش‌بینی و نمایش نتایج
    for filename in uploaded.keys():
        predicted_class, confidence = predict_image(model, plant_info["class_names"], filename)
        solution = plant_info["solutions"].get(predicted_class, "راه‌حلی تعریف نشده است.")

        print(f"Predicted Disease: {predicted_class} ({confidence:.2f}% confidence)")
        print(f"Solution: {solution}")

        # نمایش تصویر
        img = load_img(filename)
        plt.imshow(img)
        plt.axis('off')
        plt.title(f"Disease: {predicted_class}\nConfidence: {confidence:.2f}")
        plt.show()

else:
    print("انتخاب نامعتبر! لطفاً دوباره تلاش کنید.")