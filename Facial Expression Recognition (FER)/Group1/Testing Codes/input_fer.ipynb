{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = load_model('model_rafdb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion labels for FER 2013 dataset\n",
    "emotion_labels = ['Surprise', 'Fear', 'Disgust', 'Happy', 'Sad', 'Angry', 'Neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detection = cv2.CascadeClassifier('haar_cascade_face_detection.xml')\n",
    "\n",
    "settings = {\n",
    "\t'scaleFactor': 1.3, \n",
    "\t'minNeighbors': 5, \n",
    "\t'minSize': (50, 50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, face_detection, settings):\n",
    "    # Load image in color\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Image not found or unable to load.\")\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the image\n",
    "    detected_faces = face_detection.detectMultiScale(gray, **settings)\n",
    "\n",
    "    if len(detected_faces) == 0:\n",
    "        raise ValueError(\"No faces detected in the image.\")\n",
    "\n",
    "    # Process only the first detected face (optional: handle multiple faces)\n",
    "    x, y, w, h = detected_faces[0]\n",
    "\n",
    "    # Crop the detected face\n",
    "    face = gray[y + 5:y + h - 5, x + 20:x + w - 20]\n",
    "    # Resize face to 48x48\n",
    "    face = cv2.resize(face, (48, 48))\n",
    "    # Normalize pixel values\n",
    "    face = face / 255.0\n",
    "    # Expand dimensions to match model input shape (1, 48, 48, 1)\n",
    "    face = np.expand_dims(face, axis=-1)  # Add channel dimension\n",
    "    face = np.expand_dims(face, axis=0)  # Add batch dimension\n",
    "\n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(image_path):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        processed_img = preprocess_image(image_path, face_detection, settings)\n",
    "\n",
    "        # Validate processed image shape\n",
    "        if processed_img is None or len(processed_img.shape) != 4:\n",
    "            raise ValueError(f\"Invalid processed image shape: {processed_img.shape if processed_img is not None else 'None'}\")\n",
    "\n",
    "        # Debugging shapes\n",
    "        print(f\"Processed image shape: {processed_img.shape}\")\n",
    "        print(f\"Expected model input shape: {model.input_shape}\")\n",
    "\n",
    "        # Get prediction\n",
    "        prediction = model.predict(processed_img)\n",
    "\n",
    "        # Debugging prediction output\n",
    "        print(f\"Prediction output: {prediction}\")\n",
    "\n",
    "        # Get the index of the highest probability\n",
    "        emotion_idx = np.argmax(prediction)\n",
    "        # Get the corresponding label\n",
    "        emotion = emotion_labels[emotion_idx]\n",
    "\n",
    "        return emotion\n",
    "    except Exception as e:\n",
    "        print(f\"Error during emotion prediction: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion_with_probabilities(image_path):\n",
    "    try:\n",
    "        # Preprocess the image\n",
    "        processed_img = preprocess_image(image_path, face_detection, settings)\n",
    "        \n",
    "        if processed_img is None or len(processed_img.shape) != 4:\n",
    "            raise ValueError(f\"Invalid input shape: {processed_img.shape if processed_img is not None else 'None'}\")\n",
    "\n",
    "        # Print input shape for debugging\n",
    "        print(f\"Processed image shape: {processed_img.shape}\")\n",
    "        print(f\"Model expected input shape: {model.input_shape}\")\n",
    "\n",
    "        # Get prediction probabilities for all classes\n",
    "        predictions = model.predict(processed_img)[0]  # [0] to flatten the batch dimension\n",
    "        \n",
    "        # Get the index of the highest probability\n",
    "        emotion_idx = np.argmax(predictions)\n",
    "        # Get the corresponding label\n",
    "        emotion = emotion_labels[emotion_idx]\n",
    "        # Display probabilities for each class\n",
    "        probabilities = {emotion_labels[i]: predictions[i] for i in range(len(emotion_labels))}\n",
    "        return emotion, probabilities\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'test.jpg'\n",
    "predicted_emotion, class_probabilities = predict_emotion_with_probabilities(image_path)\n",
    "\n",
    "if predicted_emotion:\n",
    "    print(f\"The predicted emotion is: {predicted_emotion}\")\n",
    "    print(\"Class probabilities:\")\n",
    "    for emotion, prob in class_probabilities.items():\n",
    "        print(f\"{emotion}: {prob:.4f}\")\n",
    "else:\n",
    "    print(\"Prediction failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during emotion prediction: No faces detected in the image.\n",
      "Failed to predict emotion.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_path = 'fearful (4).jfif'\n",
    "predicted_emotion = predict_emotion(image_path)\n",
    "\n",
    "if predicted_emotion:\n",
    "    print(f\"The predicted emotion is: {predicted_emotion}\")\n",
    "else:\n",
    "    print(\"Failed to predict emotion.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
