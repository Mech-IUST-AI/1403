{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-26T12:15:35.671126Z",
     "start_time": "2025-01-26T12:15:12.250868Z"
    }
   },
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import timm\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\machine learning\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T13:21:02.531455Z",
     "start_time": "2025-01-26T13:21:02.487113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# defining a class to read images and preprocess and return label values \n",
    "class CustomDataset(Dataset):  #creating class and inherit from dataset class of pytorch lib \n",
    "    def __init__(self, Directory, transform=None): #defining inputs and methods \n",
    "        self.img_path = Directory     \n",
    "        self.transform = transform\n",
    "        self.classes = os.listdir(Directory)\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        for label, class_folder in enumerate(self.classes): #iterating over subfolders to save labels and path to a list  \n",
    "            class_folder_path = os.path.join(Directory, class_folder) \n",
    "            if os.path.isdir(class_folder_path):\n",
    "                for image_name in os.listdir(class_folder_path):\n",
    "                    image_path = os.path.join(class_folder_path, image_name)\n",
    "                    self.image_paths.append(image_path)\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "directory = r'path to dataset'\n",
    "val_directory = r'path to validation data'\n",
    "\n",
    "\n",
    "#defining preprocessing actions(resize, augment with random flip and brightness change, change data type to tensor and normalizing) \n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) #mean and standard deviation from imagenet dataset\n",
    "])\n",
    "#denormalizing process for output images\n",
    "denormalize = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0., 0., 0.], std=[1/0.229, 1/0.224, 1/0.225]),\n",
    "    transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[1., 1., 1.]),\n",
    "])\n",
    "\n",
    "#loading and preprocessing data in 32 batches and 0 parallel pools\n",
    "dataset = CustomDataset(Directory=directory, transform=preprocess)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_dataset = CustomDataset(Directory=val_directory, transform=preprocess)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   "
   ],
   "id": "9e2ee6830c7b21ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 3\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T13:42:40.007997Z",
     "start_time": "2025-01-26T13:42:39.969777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#loading EfficientNet model version b1 and pretrained weights \n",
    "model = models.efficientnet_b1(weights='IMAGENET1K_V1')\n",
    "#train model on GPU(if was available) \n",
    "device = torch.device(\"cuda\" if\n",
    "                      torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(device)\n",
    "num_classes = 11\n",
    "#changing last classifier layer of model neurons to match the number of classes \n",
    "model.classifier[1] = (\n",
    "    nn.Linear(model.classifier[1].in_features, num_classes))\n",
    "#defining loss and optimizations \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters()\n",
    "                       , lr=0.001,weight_decay=1e-4)\n",
    "num_epochs = 10\n",
    "#saving loss and accuracy\n",
    "history = {'train_loss': [], 'val_accuracy': []}\n",
    "\n",
    "#train the model \n",
    "for epoch in range(num_epochs):\n",
    "    model.train()   #set model to training mode\n",
    "    running_loss = 0.0  #reset the loss to show loss in each iteration\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad() #reset backpropagation value\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()   #computing backpropagation\n",
    "        optimizer.step()  #updating weights \n",
    "        running_loss += loss.item()\n",
    "    epoch_loss = running_loss / len(train_loader) #calculating loss of each iteration\n",
    "    \n",
    "    history['train_loss'].append(epoch_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "    #setting model to evaluation mode for validation data\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with (torch.no_grad()): #turning off gradient computation\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device),\n",
    "            labels.to(device)   #computing validation data using GPU\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1) #predicting output classes\n",
    "            total += labels.size(0)  #adding number of images in batches \n",
    "            correct += (predicted == labels).sum().item() #calculating correct predictions in integer or float format \n",
    "\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    history['val_accuracy'].append(accuracy)\n",
    "    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    \n",
    "    torch.save(model.state_dict(), f'model_epoch_{epoch+1}.pth')\n",
    "    \n",
    "#plot loss and validation accuracy    \n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training Loss and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#saving model weights\n",
    "save_path = r'path to save model'\n",
    "torch.save(model.state_dict(), save_path)"
   ],
   "id": "fbdc25f702246df3",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#loading EfficientNet model version b1 and pretrained weights \u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodels\u001B[49m\u001B[38;5;241m.\u001B[39mefficientnet_b1(weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIMAGENET1K_V1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m#train model on GPU(if was available) \u001B[39;00m\n\u001B[0;32m      4\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m\n\u001B[0;32m      5\u001B[0m                       torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'models' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T13:42:33.501454Z",
     "start_time": "2025-01-26T13:42:33.194454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#showing confusion matrix\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=val_dataset.classes, yticklabels=val_dataset.classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=val_dataset.classes))\n"
   ],
   "id": "40c6ad957a7de86",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m y_true \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      4\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m images, labels \u001B[38;5;129;01min\u001B[39;00m val_loader:\n\u001B[0;32m      8\u001B[0m         images, labels \u001B[38;5;241m=\u001B[39m images\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T13:42:26.668997Z",
     "start_time": "2025-01-26T13:42:26.552590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#loading and saving images in corresponding folders in specified directory\n",
    "\n",
    "\n",
    "test_path = r'test images paths'\n",
    "result_path = r'saved image path'\n",
    "images = os.listdir(test_path)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "\n",
    "\n",
    "for file in images:\n",
    "    print(file)\n",
    "    if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        file_path = os.path.join(test_path, file)\n",
    "        test_image = Image.open(file_path)\n",
    "        test_image = test_image.convert('RGB')\n",
    "        test_image = preprocess(test_image)\n",
    "        test_image = test_image.unsqueeze(0)\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(test_image)\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            confidence, predicted_class = torch.max(probabilities, 1)\n",
    "            confidence_percentage = confidence.item() * 100\n",
    "            \n",
    "            \n",
    "            class_label = predicted_class.item()\n",
    "            class_name = val_dataset.classes[class_label]\n",
    "            \n",
    "            \n",
    "            class_folder = os.path.join(result_path, class_name)\n",
    "            \n",
    "            if not os.path.exists(class_folder):\n",
    "                os.makedirs(class_folder) \n",
    "\n",
    "            \n",
    "            undetected_folder = os.path.join(result_path, 'undetected')\n",
    "            if not os.path.exists(undetected_folder):\n",
    "                os.makedirs(undetected_folder)\n",
    "\n",
    "            #defining a threshold for predictions \n",
    "            if confidence_percentage > 45:\n",
    "            \n",
    "                result_image_path = os.path.join(class_folder, f\"{file}\")\n",
    "                test_image_denorm = denormalize(test_image.squeeze(0))\n",
    "                test_image_denorm = torch.clamp(test_image_denorm, 0, 1)\n",
    "                test_image_pil = transforms.ToPILImage()(test_image_denorm)\n",
    "                test_image_pil.save(result_image_path)\n",
    "                \n",
    "                \n",
    "            \n",
    "                print(f\"Predicted class name: {class_name}\")\n",
    "                print(f\"Confidence: {confidence_percentage:.2f}%\\n\")\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                undetected_image_path = os.path.join(undetected_folder, file)\n",
    "                test_image_denorm = denormalize(test_image.squeeze(0))\n",
    "                test_image_denorm = torch.clamp(test_image_denorm, 0, 1)\n",
    "                test_image_pil = transforms.ToPILImage()(test_image_denorm)\n",
    "                test_image_pil.save(undetected_image_path) \n",
    "                \n",
    "                \n",
    "            \n",
    "                \n",
    "                \n",
    "                print(f\"Couldn't detect the tool for {file}\\n\")\n",
    "                \n"
   ],
   "id": "4e6f92e0a646632",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T13:38:46.518480Z",
     "start_time": "2025-01-26T13:38:46.514465Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5a2c4ebed775a616",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
